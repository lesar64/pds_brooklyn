{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e758af11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yellowcab\n",
    "from yellowcab.io import get_data_path, read_all_files, filter_borough, add_duration, add_location, add_weekend, add_namings, add_datetime_columns\n",
    "import os\n",
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "98899462",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading the raw data\n",
      "Filtering the borough\n",
      "Adding duration for filtering\n",
      "Filtering the extreme values\n",
      "Augmenting the raw data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\OneDrive - Universität zu Köln\\Uni\\PDS\\Code\\yellowcab\\io\\utils.py:52: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  geo_data[\"longitude\"] = gdf.centroid.x\n",
      "D:\\OneDrive - Universität zu Köln\\Uni\\PDS\\Code\\yellowcab\\io\\utils.py:53: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  geo_data[\"latitude\"] = gdf.centroid.y\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trips with location_id above 263 were dropped, since there is no matching geo data.\n",
      "Resetting index and saving\n",
      "Done. File is at:D:\\OneDrive - Universität zu Köln\\Uni\\PDS\\Code\\notebooks\\1_exploration\\..\\..\\data\\input\\trip_data\\clean_data.parquet\n"
     ]
    }
   ],
   "source": [
    "yellowcab.io.create_clean_trip_dataset(save=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8e2848c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = yellowcab.io.read_all_files(\"parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading the raw data\n",
      "Was 23838931 long before filtering borough\n",
      "Filtered 16218357 values out, or 68.03307161717947\n",
      "\n",
      "Adding duration for filtering\n",
      "Filtering the extreme values\n",
      "Was 7620574 long before filtering pickup in 2020\n",
      "Filtered 92 values out, or 0.001207258140922193\n",
      "\n",
      "Was 7620482 long before filtering dropoff in 2020\n",
      "Filtered 77 values out, or 0.0010104347730235436\n",
      "\n",
      "Was 7620405 long before filtering passengers\n",
      "Filtered 154638 values out, or 2.0292622242518608\n",
      "\n",
      "Was 7465767 long before filtering distance\n",
      "Filtered 91196 values out, or 1.2215221825165452\n",
      "\n",
      "Was 7374571 long before filtering fare\n",
      "Filtered 29047 values out, or 0.3938805389493165\n",
      "\n",
      "Was 7345524 long before filtering tip\n",
      "Filtered 0 values out, or 0.0\n",
      "\n",
      "Was 7345524 long before filtering tolls\n",
      "Filtered 0 values out, or 0.0\n",
      "\n",
      "Was 7345524 long before filtering total\n",
      "Filtered 0 values out, or 0.0\n",
      "\n",
      "Was 7345524 long before filtering congestion\n",
      "Filtered 0 values out, or 0.0\n",
      "\n",
      "Was 7345524 long before filtering duration hard\n",
      "Filtered 16068 values out, or 0.218745456416724\n",
      "\n",
      "Was 7329456 long before filtering duration soft\n",
      "Filtered 1599 values out, or 0.02181608021113709\n",
      "\n",
      "Augmenting the raw data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\OneDrive - Universität zu Köln\\Uni\\PDS\\Code\\yellowcab\\io\\utils.py:52: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  geo_data[\"longitude\"] = gdf.centroid.x\n",
      "D:\\OneDrive - Universität zu Köln\\Uni\\PDS\\Code\\yellowcab\\io\\utils.py:53: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  geo_data[\"latitude\"] = gdf.centroid.y\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trips with location_id above 263 were dropped, since there is no matching geo data.\n",
      "Resetting index and saving\n"
     ]
    }
   ],
   "source": [
    "def create_clean_trip_dataset(soft_duration_cutoff=13000, borough='Brooklyn', save=False, ret=False):\n",
    "    # load data\n",
    "    print('Reading the raw data')\n",
    "    df = read_all_files('parquet', raw=True)\n",
    "\n",
    "    # filter borough\n",
    "    length = len(df)\n",
    "    df = filter_borough(df, borough)\n",
    "    diff = length - len(df)\n",
    "    print('Was ' + str(length) + ' long before filtering borough')\n",
    "    print('Filtered ' + str(diff) + ' values out, or ' + str((diff / length) * 100))\n",
    "    print('')\n",
    "    length = len(df)\n",
    "\n",
    "    # add duration\n",
    "    print('Adding duration for filtering')\n",
    "    df = add_duration(df)\n",
    "\n",
    "    # filter negative and extrem values\n",
    "    print('Filtering the extreme values')\n",
    "    df = df[df['tpep_pickup_datetime'].between('2020-01-01 00:00:00', '2020-12-31 23:59:59')]\n",
    "    diff = length - len(df)\n",
    "    print('Was ' + str(length) + ' long before filtering pickup in 2020')\n",
    "    print('Filtered ' + str(diff) + ' values out, or ' + str((diff / length) * 100))\n",
    "    print('')\n",
    "    length = len(df)\n",
    "\n",
    "    df = df[df['tpep_dropoff_datetime'].between('2020-01-01 00:00:00', '2020-12-31 23:59:59')]\n",
    "    diff = length - len(df)\n",
    "    print('Was ' + str(length) + ' long before filtering dropoff in 2020')\n",
    "    print('Filtered ' + str(diff) + ' values out, or ' + str((diff / length) * 100))\n",
    "    print('')\n",
    "    length = len(df)\n",
    "\n",
    "    df = df[df['passenger_count'] > 0]\n",
    "    diff = length - len(df)\n",
    "    print('Was ' + str(length) + ' long before filtering passengers')\n",
    "    print('Filtered ' + str(diff) + ' values out, or ' + str((diff / length) * 100))\n",
    "    print('')\n",
    "    length = len(df)\n",
    "\n",
    "    df = df[df['trip_distance'].between(0.01, 1000)]\n",
    "    diff = length - len(df)\n",
    "    print('Was ' + str(length) + ' long before filtering distance')\n",
    "    print('Filtered ' + str(diff) + ' values out, or ' + str((diff / length) * 100))\n",
    "    print('')\n",
    "    length = len(df)\n",
    "\n",
    "    df = df[df['fare_amount'].between(0.01, 7000)]\n",
    "    diff = length - len(df)\n",
    "    print('Was ' + str(length) + ' long before filtering fare')\n",
    "    print('Filtered ' + str(diff) + ' values out, or ' + str((diff / length) * 100))\n",
    "    print('')\n",
    "    length = len(df)\n",
    "\n",
    "    df = df[df['tip_amount'] >= 0]\n",
    "    diff = length - len(df)\n",
    "    print('Was ' + str(length) + ' long before filtering tip')\n",
    "    print('Filtered ' + str(diff) + ' values out, or ' + str((diff / length) * 100))\n",
    "    print('')\n",
    "    length = len(df)\n",
    "\n",
    "    df = df[df['tolls_amount'] >= 0]\n",
    "    diff = length - len(df)\n",
    "    print('Was ' + str(length) + ' long before filtering tolls')\n",
    "    print('Filtered ' + str(diff) + ' values out, or ' + str((diff / length) * 100))\n",
    "    print('')\n",
    "    length = len(df)\n",
    "\n",
    "    df = df[df['total_amount'].between(0, 7000)]\n",
    "    diff = length - len(df)\n",
    "    print('Was ' + str(length) + ' long before filtering total')\n",
    "    print('Filtered ' + str(diff) + ' values out, or ' + str((diff / length) * 100))\n",
    "    print('')\n",
    "    length = len(df)\n",
    "\n",
    "    df = df[df['congestion_surcharge'] >= 0]\n",
    "    diff = length - len(df)\n",
    "    print('Was ' + str(length) + ' long before filtering congestion')\n",
    "    print('Filtered ' + str(diff) + ' values out, or ' + str((diff / length) * 100))\n",
    "    print('')\n",
    "    length = len(df)\n",
    "\n",
    "    df = df[df['duration'].between(1, 57600)]  # cut off at 16h\n",
    "    diff = length - len(df)\n",
    "    print('Was ' + str(length) + ' long before filtering duration hard')\n",
    "    print('Filtered ' + str(diff) + ' values out, or ' + str((diff / length) * 100))\n",
    "    print('')\n",
    "    length = len(df)\n",
    "\n",
    "\n",
    "    midnight = dt.datetime(2020, 1, 1, hour=0, minute=0, second=0)\n",
    "    df = df[((df['duration'] < soft_duration_cutoff) |\n",
    "             ((df['tpep_pickup_datetime'].dt.time != midnight.time()) &\n",
    "             (df['tpep_dropoff_datetime'].dt.time != midnight.time())))]\n",
    "    diff = length - len(df)\n",
    "    print('Was ' + str(length) + ' long before filtering duration soft')\n",
    "    print('Filtered ' + str(diff) + ' values out, or ' + str((diff / length) * 100))\n",
    "    print('')\n",
    "    length = len(df)\n",
    "\n",
    "    # add columns\n",
    "    print('Augmenting the raw data')\n",
    "    df = add_datetime_columns(df)\n",
    "    df = add_weekend(df)\n",
    "    df = add_location(df)\n",
    "    df = add_namings(df)\n",
    "\n",
    "    print('Resetting index and saving')\n",
    "    df.reset_index(inplace=True, drop=True)\n",
    "    if save:\n",
    "        df.to_parquet(os.path.join(get_data_path(), \"input\", \"trip_data\", \"clean_data.parquet\"))\n",
    "        print('Done. File is at:' + os.path.join(get_data_path(), \"input\", \"trip_data\", \"clean_data.parquet\"))\n",
    "\n",
    "    if ret:\n",
    "        return df\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "create_clean_trip_dataset()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}